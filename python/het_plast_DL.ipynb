{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "import fastdyn_fic_dmf as dmf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Fetch default parameters\n",
    "import tracemalloc\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import zscore, pearsonr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mat73\n",
    "# Helper functions\n",
    "def compute_fcd(data, wsize, overlap, isubdiag):\n",
    "    T, N = data.shape\n",
    "    win_start = np.arange(0, T - wsize - 1, wsize - overlap)\n",
    "    nwins = len(win_start)\n",
    "    fcd = np.zeros((len(isubdiag[0]), nwins))\n",
    "    #print(fcd.shape)\n",
    "    #print(data.shape)\n",
    "    #print((data[win_start[2]:win_start[2] + wsize + 1, :]).shape)\n",
    "    for i in range(nwins):\n",
    "        tmp = data[win_start[i]:win_start[i] + wsize + 1, :]\n",
    "        cormat = np.corrcoef(tmp.T)\n",
    "        fcd[:, i] = cormat[isubdiag[0],isubdiag[1]]\n",
    "    return fcd\n",
    "\n",
    "\n",
    "C = loadmat('./data/DTI_fiber_consensus_HCP.mat')['connectivity'][:200, :200]\n",
    "C = 0.2*C/np.max(C)\n",
    "N = C.shape[0]\n",
    "\n",
    "G_VAL = 3.5\n",
    "NB_STEPS = 15000\n",
    "BURNOUT = 5000\n",
    "SEED_BASE = 1  # Base seed value\n",
    "\n",
    "# Define the list of LR values you want to test\n",
    "lr_values = [500, 15000, 20000, 25000]\n",
    "\n",
    "# Assuming N is defined globally (number of regions)\n",
    "N = 200  # adjust accordingly if different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sim_run(G_VAL, LR, SEED, NB_STEPS=50000):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "    G_VAL: float, global coupling\n",
    "    LR: array, learning rate (Homogeneous or heterogenos. Decay will be calcualted for each region with this)\n",
    "    SEED: int, random seed\n",
    "    OUTPUTS:\n",
    "    rates_dyn: np.array, dynamic of rates\n",
    "    rates_inh_dyn: np.array, dynamic of inhibitory rates\n",
    "    bold_dyn: np.array, dynamic of BOLD signal\n",
    "    fic_t_dyn: np.array, dynamic of FIC\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    params = dmf.default_params(C=C)\n",
    "    fit_res = np.load(\"./data/fit_res_3-44.npy\")\n",
    "    b = fit_res[0] # First element is the slope\n",
    "    a = fit_res[1]\n",
    "    params['G'] = G_VAL\n",
    "    params['seed'] = SEED\n",
    "    params['obj_rate'] = 3.44\n",
    "    DECAY = np.exp(a+np.log(LR)*b)    \n",
    "    params['lr_vector'] = LR\n",
    "    params['taoj_vector'] =  DECAY\n",
    "    params['J'] = 0.75*params['G']*params['C'].sum(axis=0).squeeze() + 1\n",
    "    params[\"with_decay\"] = True\n",
    "    params[\"with_plasticity\"] = True\n",
    "    params['return_bold'] = False\n",
    "    params[\"return_fic\"] = False\n",
    "    params[\"return_rate\"] = True\n",
    "    rates_dyn, rates_inh_dyn, _, fic_t_dyn = dmf.run(params, NB_STEPS)\n",
    "    return rates_dyn, rates_inh_dyn, fic_t_dyn\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_along_axis(axis=0):\n",
    "    def decorator(func):\n",
    "        def wrapper(data, *args, **kwargs):\n",
    "            # if the data is 1D, just call the function directly\n",
    "            if data.ndim == 1:\n",
    "                return func(data, *args, **kwargs)\n",
    "            # otherwise, apply the function along the specified axis\n",
    "            return np.apply_along_axis(func, axis, data, *args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@vectorize_along_axis(axis=0)\n",
    "def get_autcorr(rates):\n",
    "    \"\"\"Get the autocorrelation function from a 1D rates vector.\"\"\"\n",
    "    signal = rates - np.mean(rates)\n",
    "    # Calculate autocorrelation function (full convolution)\n",
    "    autocorr = np.correlate(signal, signal, mode='full')\n",
    "    # Normalize: divide by the variance and length of the signal\n",
    "    autocorr = autocorr / (np.var(signal) * len(signal))\n",
    "    # Only keep the second half (non-negative lags)\n",
    "    autocorr = autocorr[len(signal)-1:]\n",
    "    return autocorr\n",
    "# create a function that computes and plots the autocorrelation of the average rates\n",
    "def plot_autocorr(rates, title):\n",
    "    autocorr = get_autcorr(np.mean(rates, axis=0))\n",
    "    lags = np.arange(0, len(autocorr))\n",
    "    plt.plot(lags, autocorr)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved homogeneous simulation results for LR = 500 to ./Results/homogeneous/g_3.5_lr_500.npy\n",
      "Saved homogeneous simulation results for LR = 15000 to ./Results/homogeneous/g_3.5_lr_15000.npy\n",
      "Saved homogeneous simulation results for LR = 20000 to ./Results/homogeneous/g_3.5_lr_20000.npy\n",
      "Saved homogeneous simulation results for LR = 25000 to ./Results/homogeneous/g_3.5_lr_25000.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "def run_simulation(idx, lr):\n",
    "    SEED = SEED_BASE + idx\n",
    "    # Create a homogeneous LR vector for all regions\n",
    "    LR_VEC = np.ones(N) * lr\n",
    "    # Run simulation (assuming sim_run returns rates, inhibitory rates and fic_t in that order)\n",
    "    rates, _, _ = sim_run(G_VAL, LR_VEC, SEED, NB_STEPS)\n",
    "    # Discard burnout period\n",
    "    return rates[:, BURNOUT:]\n",
    "\n",
    "for lr in lr_values:\n",
    "    # Execute 100 simulation runs in parallel.\n",
    "    simulations = Parallel(n_jobs=16)(delayed(run_simulation)(idx, lr) for idx in range(100))\n",
    "    rates_all = np.array(simulations)\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(\"./Results/homogeneous\", exist_ok=True)\n",
    "    filename = f\"./Results/homogeneous/g_{G_VAL}_lr_{lr}.npy\"\n",
    "    np.save(filename, rates_all)\n",
    "    print(f\"Saved homogeneous simulation results for LR = {lr} to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [1/300], Loss: 1.1209\n",
      "Epoch [1/2], Step [6/300], Loss: 1379486464.0000\n",
      "Epoch [1/2], Step [11/300], Loss: 953749760.0000\n",
      "Epoch [1/2], Step [16/300], Loss: 1178120960.0000\n",
      "Epoch [1/2], Step [21/300], Loss: 144732128.0000\n",
      "Epoch [1/2], Step [26/300], Loss: 1223536384.0000\n",
      "Epoch [1/2], Step [31/300], Loss: 201085760.0000\n",
      "Epoch [1/2], Step [36/300], Loss: 151853952.0000\n",
      "Epoch [1/2], Step [41/300], Loss: 123347840.0000\n",
      "Epoch [1/2], Step [46/300], Loss: 40846080.0000\n",
      "Epoch [1/2], Step [51/300], Loss: 122252744.0000\n",
      "Epoch [1/2], Step [56/300], Loss: 22803616.0000\n",
      "Epoch [1/2], Step [61/300], Loss: 25785512.0000\n",
      "Epoch [1/2], Step [66/300], Loss: 25566464.0000\n",
      "Epoch [1/2], Step [71/300], Loss: 17588518.0000\n",
      "Epoch [1/2], Step [76/300], Loss: 17735226.0000\n",
      "Epoch [1/2], Step [81/300], Loss: 8877123.0000\n",
      "Epoch [1/2], Step [86/300], Loss: 7568984.5000\n",
      "Epoch [1/2], Step [91/300], Loss: 17894426.0000\n",
      "Epoch [1/2], Step [96/300], Loss: 10067254.0000\n",
      "Epoch [1/2], Step [101/300], Loss: 2179403.7500\n",
      "Epoch [1/2], Step [106/300], Loss: 2536668.2500\n",
      "Epoch [1/2], Step [111/300], Loss: 2020996.0000\n",
      "Epoch [1/2], Step [116/300], Loss: 1939248.6250\n",
      "Epoch [1/2], Step [121/300], Loss: 1194064.5000\n",
      "Epoch [1/2], Step [126/300], Loss: 395667.0000\n",
      "Epoch [1/2], Step [131/300], Loss: 301210.9375\n",
      "Epoch [1/2], Step [136/300], Loss: 134188.9062\n",
      "Epoch [1/2], Step [141/300], Loss: 151878.2188\n",
      "Epoch [1/2], Step [146/300], Loss: 72214.2500\n",
      "Epoch [1/2], Step [151/300], Loss: 35780.4766\n",
      "Epoch [1/2], Step [156/300], Loss: 34787.0742\n",
      "Epoch [1/2], Step [161/300], Loss: 16001.9580\n",
      "Epoch [1/2], Step [166/300], Loss: 15857.5107\n",
      "Epoch [1/2], Step [171/300], Loss: 9249.7051\n",
      "Epoch [1/2], Step [176/300], Loss: 4780.3389\n",
      "Epoch [1/2], Step [181/300], Loss: 3481.5388\n",
      "Epoch [1/2], Step [186/300], Loss: 1769.0902\n",
      "Epoch [1/2], Step [191/300], Loss: 1410.7925\n",
      "Epoch [1/2], Step [196/300], Loss: 867.7737\n",
      "Epoch [1/2], Step [201/300], Loss: 656.1192\n",
      "Epoch [1/2], Step [206/300], Loss: 387.8506\n",
      "Epoch [1/2], Step [211/300], Loss: 271.3540\n",
      "Epoch [1/2], Step [216/300], Loss: 174.7748\n",
      "Epoch [1/2], Step [221/300], Loss: 106.8994\n",
      "Epoch [1/2], Step [226/300], Loss: 74.3962\n",
      "Epoch [1/2], Step [231/300], Loss: 34.7477\n",
      "Epoch [1/2], Step [236/300], Loss: 23.2555\n",
      "Epoch [1/2], Step [241/300], Loss: 14.6951\n",
      "Epoch [1/2], Step [246/300], Loss: 9.9892\n",
      "Epoch [1/2], Step [251/300], Loss: 5.5494\n",
      "Epoch [1/2], Step [256/300], Loss: 3.3630\n",
      "Epoch [1/2], Step [261/300], Loss: 2.8246\n",
      "Epoch [1/2], Step [266/300], Loss: 1.8795\n",
      "Epoch [1/2], Step [271/300], Loss: 1.9588\n",
      "Epoch [1/2], Step [276/300], Loss: 1.3433\n",
      "Epoch [1/2], Step [281/300], Loss: 1.4004\n",
      "Epoch [1/2], Step [286/300], Loss: 1.2239\n",
      "Epoch [1/2], Step [291/300], Loss: 1.2510\n",
      "Epoch [1/2], Step [296/300], Loss: 1.2588\n",
      "=== End of Epoch 1, Avg Loss: 112867766.0468 ===\n",
      "Epoch [2/2], Step [1/300], Loss: 1.2869\n",
      "Epoch [2/2], Step [6/300], Loss: 1.0841\n",
      "Epoch [2/2], Step [11/300], Loss: 1.1332\n",
      "Epoch [2/2], Step [16/300], Loss: 1.2554\n",
      "Epoch [2/2], Step [21/300], Loss: 0.9151\n",
      "Epoch [2/2], Step [26/300], Loss: 0.8818\n",
      "Epoch [2/2], Step [31/300], Loss: 1.2532\n",
      "Epoch [2/2], Step [36/300], Loss: 0.9553\n",
      "Epoch [2/2], Step [41/300], Loss: 1.4675\n",
      "Epoch [2/2], Step [46/300], Loss: 1.1956\n",
      "Epoch [2/2], Step [51/300], Loss: 1.1569\n",
      "Epoch [2/2], Step [56/300], Loss: 1.1436\n",
      "Epoch [2/2], Step [61/300], Loss: 1.1986\n",
      "Epoch [2/2], Step [66/300], Loss: 1.2016\n",
      "Epoch [2/2], Step [71/300], Loss: 1.2448\n",
      "Epoch [2/2], Step [76/300], Loss: 1.0427\n",
      "Epoch [2/2], Step [81/300], Loss: 1.3088\n",
      "Epoch [2/2], Step [86/300], Loss: 0.9747\n",
      "Epoch [2/2], Step [91/300], Loss: 1.2244\n",
      "Epoch [2/2], Step [96/300], Loss: 0.9405\n",
      "Epoch [2/2], Step [101/300], Loss: 1.2042\n",
      "Epoch [2/2], Step [106/300], Loss: 1.2294\n",
      "Epoch [2/2], Step [111/300], Loss: 1.2512\n",
      "Epoch [2/2], Step [116/300], Loss: 1.3036\n",
      "Epoch [2/2], Step [121/300], Loss: 1.1330\n",
      "Epoch [2/2], Step [126/300], Loss: 1.1743\n",
      "Epoch [2/2], Step [131/300], Loss: 1.1897\n",
      "Epoch [2/2], Step [136/300], Loss: 1.0098\n",
      "Epoch [2/2], Step [141/300], Loss: 0.9961\n",
      "Epoch [2/2], Step [146/300], Loss: 0.9788\n",
      "Epoch [2/2], Step [151/300], Loss: 1.2875\n",
      "Epoch [2/2], Step [156/300], Loss: 1.4799\n",
      "Epoch [2/2], Step [161/300], Loss: 1.2117\n",
      "Epoch [2/2], Step [166/300], Loss: 1.4957\n",
      "Epoch [2/2], Step [171/300], Loss: 1.4935\n",
      "Epoch [2/2], Step [176/300], Loss: 1.3025\n",
      "Epoch [2/2], Step [181/300], Loss: 1.4755\n",
      "Epoch [2/2], Step [186/300], Loss: 1.2434\n",
      "Epoch [2/2], Step [191/300], Loss: 0.9847\n",
      "Epoch [2/2], Step [196/300], Loss: 1.1592\n",
      "Epoch [2/2], Step [201/300], Loss: 1.2703\n",
      "Epoch [2/2], Step [206/300], Loss: 1.2894\n",
      "Epoch [2/2], Step [211/300], Loss: 1.0331\n",
      "Epoch [2/2], Step [216/300], Loss: 0.8794\n",
      "Epoch [2/2], Step [221/300], Loss: 1.4630\n",
      "Epoch [2/2], Step [226/300], Loss: 1.2679\n",
      "Epoch [2/2], Step [231/300], Loss: 1.0409\n",
      "Epoch [2/2], Step [236/300], Loss: 1.4629\n",
      "Epoch [2/2], Step [241/300], Loss: 0.8733\n",
      "Epoch [2/2], Step [246/300], Loss: 1.4475\n",
      "Epoch [2/2], Step [251/300], Loss: 1.4328\n",
      "Epoch [2/2], Step [256/300], Loss: 1.3173\n",
      "Epoch [2/2], Step [261/300], Loss: 1.4870\n",
      "Epoch [2/2], Step [266/300], Loss: 1.1738\n",
      "Epoch [2/2], Step [271/300], Loss: 1.2259\n",
      "Epoch [2/2], Step [276/300], Loss: 1.2737\n",
      "Epoch [2/2], Step [281/300], Loss: 1.2165\n",
      "Epoch [2/2], Step [286/300], Loss: 1.3368\n",
      "Epoch [2/2], Step [291/300], Loss: 1.2064\n",
      "Epoch [2/2], Step [296/300], Loss: 0.8665\n",
      "=== End of Epoch 2, Avg Loss: 1.2350 ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.signal as signal\n",
    "\n",
    "############################\n",
    "# 1) PhaseDiffDataset\n",
    "############################\n",
    "class PhaseDiffDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Converts raw 'rates' of shape (N, 200, 50000) into sequences of 20 phase-difference\n",
    "    matrices, each 200x200. Final shape: (N, 20, 1, 200, 200).\n",
    "    \"\"\"\n",
    "    def __init__(self, rates, num_timepoints=20):\n",
    "        \"\"\"\n",
    "        rates: NumPy array of shape (N=150, 200, 50000).\n",
    "        num_timepoints: how many equally spaced time points to sample for each simulation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_timepoints = num_timepoints\n",
    "        self.phase_diff = self._create_phase_diff_matrices(rates, num_timepoints)\n",
    "\n",
    "    def _create_phase_diff_matrices(self, rates, num_matrices):\n",
    "        \"\"\"\n",
    "        1) Apply Hilbert transform -> instantaneous phase\n",
    "        2) Sample 'num_matrices' time points from each simulation\n",
    "        3) Build 200x200 phase-difference matrix at each time point\n",
    "        Returns a NumPy array of shape (N, num_matrices, 1, 200, 200).\n",
    "        \"\"\"\n",
    "        N, num_channels, timesteps = rates.shape  # e.g. (150, 200, 50000)\n",
    "\n",
    "        # Hilbert transform along time axis -> instantaneous phase\n",
    "        analytic_signal = signal.hilbert(rates, axis=2)    # shape (N, 200, 50000)\n",
    "        inst_phase = np.angle(analytic_signal)             # same shape\n",
    "\n",
    "        # Time indices for sampling\n",
    "        time_indices = np.linspace(0, timesteps - 1, num_matrices, dtype=int)\n",
    "\n",
    "        all_phase_diff = []\n",
    "        for i in range(N):\n",
    "            # Extract the phase for the ith simulation -> shape (200, 50000)\n",
    "            phase_i = inst_phase[i]\n",
    "\n",
    "            # Collect phase-diff matrices for the 20 time points\n",
    "            diff_list = []\n",
    "            for t in time_indices:\n",
    "                phase_t = phase_i[:, t]  # shape (200,)\n",
    "                diff_matrix = phase_t[:, None] - phase_t[None, :]  # (200, 200)\n",
    "                diff_list.append(diff_matrix[None, ...])          # (1, 200, 200)\n",
    "\n",
    "            # Shape -> (20, 200, 200) for this simulation\n",
    "            diff_array = np.concatenate(diff_list, axis=0)\n",
    "            # Keep for each simulation\n",
    "            all_phase_diff.append(diff_array[None, ...])   # (1, 20, 200, 200)\n",
    "\n",
    "        # Combine => (N, 20, 200, 200)\n",
    "        all_phase_diff = np.concatenate(all_phase_diff, axis=0)\n",
    "        # Add channel dimension => (N, 20, 1, 200, 200)\n",
    "        all_phase_diff = all_phase_diff[:, :, None, :, :]\n",
    "        return all_phase_diff\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.phase_diff.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a float tensor of shape (20, 1, 200, 200)\n",
    "        return torch.from_numpy(self.phase_diff[idx]).float()\n",
    "\n",
    "\n",
    "############################\n",
    "# 2) ConvLSTM building blocks\n",
    "############################\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single ConvLSTM cell for 2D frames.\n",
    "    Input shape: (B, in_channels, H, W)\n",
    "    Output: h_next, c_next\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=input_channels + hidden_channels,\n",
    "            out_channels=4 * hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        # x, h => (B, channels, H, W)\n",
    "        combined = torch.cat([x, h], dim=1)  # concat along channel axis\n",
    "        gates = self.conv(combined)         # => (B, 4*hidden_channels, H, W)\n",
    "        \n",
    "        # Split into i, f, g, o\n",
    "        i, f, g, o = torch.split(gates, self.hidden_channels, dim=1)\n",
    "        \n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        g = torch.tanh(g)\n",
    "        o = torch.sigmoid(o)\n",
    "        \n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        \n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, spatial_size):\n",
    "        height, width = spatial_size\n",
    "        device = next(self.parameters()).device\n",
    "        h = torch.zeros(batch_size, self.hidden_channels, height, width, device=device)\n",
    "        c = torch.zeros(batch_size, self.hidden_channels, height, width, device=device)\n",
    "        return h, c\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Single-layer ConvLSTM that processes a sequence of 2D frames:\n",
    "      Input shape: (B, T, in_channels, H, W)\n",
    "      Output: \n",
    "        if return_sequence=True -> (B, T, hidden_channels, H, W)\n",
    "        else -> final (h, c)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size=3, padding=1, return_sequence=False):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.cell = ConvLSTMCell(input_channels, hidden_channels, kernel_size, padding)\n",
    "        self.return_sequence = return_sequence\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, timesteps, _, height, width = x.size()\n",
    "        h, c = self.cell.init_hidden(batch_size, (height, width))\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(timesteps):\n",
    "            x_t = x[:, t]          # shape: (B, in_channels, H, W)\n",
    "            h, c = self.cell(x_t, h, c)\n",
    "            if self.return_sequence:\n",
    "                outputs.append(h.unsqueeze(1))  # store each time step's h\n",
    "        \n",
    "        if self.return_sequence:\n",
    "            return torch.cat(outputs, dim=1), (h, c)\n",
    "        else:\n",
    "            return h, c\n",
    "\n",
    "############################\n",
    "# 3) ConvLSTMAutoEncoder\n",
    "############################\n",
    "class ConvLSTMAutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Shallow autoencoder with:\n",
    "      - encoder_lstm (no sequence output)\n",
    "      - decoder_lstm (returns the entire sequence)\n",
    "      - final conv to map hidden_channels -> input_channels\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, hidden_channels=8, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.encoder_lstm = ConvLSTM(\n",
    "            input_channels=input_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            return_sequence=False\n",
    "        )\n",
    "        self.decoder_lstm = ConvLSTM(\n",
    "            input_channels=hidden_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            return_sequence=True\n",
    "        )\n",
    "        self.conv_out = nn.Conv2d(hidden_channels, input_channels, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T=20, in_channels=1, H=200, W=200)\n",
    "        Returns reconstruction => same shape (B, T, 1, H, W).\n",
    "        \"\"\"\n",
    "        B, T, C, H, W = x.shape\n",
    "        \n",
    "        # --- Encoder ---\n",
    "        h_enc, c_enc = self.encoder_lstm(x)   # final hidden/cell from encoder\n",
    "        \n",
    "        # --- Decoder ---\n",
    "        # We'll feed zeros at each time step (could use teacher forcing if desired)\n",
    "        decoder_input = torch.zeros((B, T, self.decoder_lstm.hidden_channels, H, W), \n",
    "                                    device=x.device, dtype=x.dtype)\n",
    "        h_dec, c_dec = (h_enc, c_enc)\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(T):\n",
    "            x_t = decoder_input[:, t]\n",
    "            h_dec, c_dec = self.decoder_lstm.cell(x_t, h_dec, c_dec)\n",
    "            outputs.append(h_dec.unsqueeze(1))\n",
    "        \n",
    "        # shape => (B, T, hidden_channels, H, W)\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        \n",
    "        # map each frame to 1 channel\n",
    "        recon_frames = []\n",
    "        for t in range(T):\n",
    "            out_t = self.conv_out(outputs[:, t])\n",
    "            recon_frames.append(out_t.unsqueeze(1))\n",
    "        \n",
    "        # shape => (B, T, 1, H, W)\n",
    "        recon_sequence = torch.cat(recon_frames, dim=1)\n",
    "        return recon_sequence\n",
    "\n",
    "############################\n",
    "# 4) Main script\n",
    "############################\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparams\n",
    "    batch_size = 2\n",
    "    lr = 1e-3\n",
    "    num_epochs = 2\n",
    "    lr_values = [100,200,1000,10000,15000,20000]\n",
    "    # Load rates data. Pile all the different LR values along the first axis\n",
    "    rates = np.zeros((len(lr_values)*100, 200, NB_STEPS-BURNOUT))\n",
    "    for lr in lr_values:\n",
    "        filename = f\"./Results/homogeneous/g_{G_VAL}_lr_{lr}.npy\"\n",
    "        rates_lr = np.load(filename)\n",
    "        rates[(lr_values.index(lr)*100):((lr_values.index(lr)+1)*100)] = rates_lr\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # Build dataset -> shape (len(lr_values)*100, 20, 1, 200, 200)\n",
    "    dataset = PhaseDiffDataset(rates, num_timepoints=20)\n",
    "    \n",
    "    # Wrap in DataLoader\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Instantiate model\n",
    "    model = ConvLSTMAutoEncoder(input_channels=1, hidden_channels=8)  # smaller hidden_channels to save memory\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(loader):\n",
    "            # batch: (B, 20, 1, 200, 200)\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            recon = model(batch)    # shape (B, 20, 1, 200, 200)\n",
    "            loss = criterion(recon, batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            if i % 5 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(loader)}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        avg_loss = total_loss / len(loader)\n",
    "        print(f\"=== End of Epoch {epoch+1}, Avg Loss: {avg_loss:.4f} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"./Results/convlstm_autoencoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Suppose you have these modules from your previous code\n",
    "# from your_module import ConvLSTMAutoEncoder, PhaseDiffDataset, project_to_latent, visualize_latent_space\n",
    "\n",
    "\n",
    "# 1) Suppose we have a trained model (just re-instantiate a model here for demonstration)\n",
    "model = ConvLSTMAutoEncoder(input_channels=1, hidden_channels=8)\n",
    "# You would typically do: model.load_state_dict(torch.load(\"my_trained_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# 2) Create or load your new data batch. \n",
    "#    load simulations with lr 500 and 25000\n",
    "rates_500 = np.load(\"./Results/homogeneous/g_3.5_lr_500.npy\")\n",
    "rates_25000 = np.load(\"./Results/homogeneous/g_3.5_lr_25000.npy\")\n",
    "new_data = np.concatenate([rates_500, rates_25000], axis=0)\n",
    "test_data = PhaseDiffDataset(new_data, num_timepoints=20)\n",
    "#test_data = test_data[:, :, None, :, :]  # add channel dimension\n",
    "\n",
    "\n",
    "# 3) We can feed the entire 50 items in one go or in smaller batches. \n",
    "#    Let's do it in smaller batches to avoid running out of memory:\n",
    "batch_size = 5\n",
    "loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.concatenate([rates_500[:20], rates_25000[:20]], axis=0)\n",
    "test_data = PhaseDiffDataset(new_data, num_timepoints=20)\n",
    "#test_data = test_data[:, :, None, :, :]  # add channel dimension\n",
    "\n",
    "\n",
    "# 3) We can feed the entire 50 items in one go or in smaller batches. \n",
    "#    Let's do it in smaller batches to avoid running out of memory:\n",
    "batch_size = 5\n",
    "loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent representation shape: torch.Size([40, 320000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "latent_all = []\n",
    "for batch in loader:\n",
    "    # batch: shape (B, 20, 1, 200, 200)\n",
    "    with torch.no_grad():\n",
    "        h_enc, c_enc = model.encoder_lstm(batch)\n",
    "        # shape => (B, hidden_channels, 200, 200)\n",
    "        B, hidden_dim, H, W = h_enc.shape\n",
    "        \n",
    "        # Flatten\n",
    "        latent_flat = h_enc.view(B, -1)  # shape => (B, hidden_dim * H * W)\n",
    "        latent_all.append(latent_flat)\n",
    "\n",
    "# 4) Combine all batches into one big tensor\n",
    "latent_all = torch.cat(latent_all, dim=0)  # shape => (50, hidden_dim * H * W)\n",
    "\n",
    "print(\"Latent representation shape:\", latent_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 320000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent representation shape: torch.Size([200, 320000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m X \u001b[38;5;241m=\u001b[39m latent_all\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     20\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m X_emb \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 6) Plot the 2D embedding\u001b[39;00m\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/fic_h/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/fic_h/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fic_h/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1178\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m-> 1178\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/miniforge3/envs/fic_h/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:997\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[t-SNE] Indexed \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m samples in \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124ms...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    992\u001b[0m             n_samples, duration\n\u001b[1;32m    993\u001b[0m         )\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    996\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 997\u001b[0m distances_nn \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m duration \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/miniforge3/envs/fic_h/lib/python3.10/site-packages/sklearn/neighbors/_base.py:1030\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_queries \u001b[38;5;241m*\u001b[39m n_neighbors)\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1030\u001b[0m     A_data, A_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(A_data)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/fic_h/lib/python3.10/site-packages/sklearn/neighbors/_base.py:869\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    862\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    865\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    866\u001b[0m     )\n\u001b[1;32m    867\u001b[0m )\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    881\u001b[0m ):\n\u001b[1;32m    882\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    883\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    884\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/fic_h/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:293\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin64\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    282\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    283\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    290\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly float64 or float32 datasets pairs are supported at this time, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot: X.dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Y.dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:550\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:568\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:857\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.EuclideanArgKmin32.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_base.pyx:509\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._base._sqeuclidean_row_norms32\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/fic_h/lib/python3.10/site-packages/scipy/sparse/_base.py:1400\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A namespace class to separate sparray from spmatrix\"\"\"\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m \n\u001b[1;32m   1403\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 5) Optionally apply t-SNE for 2D visualization\n",
    "X = latent_all.cpu().numpy()\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_emb = tsne.fit_transform(X)\n",
    "\n",
    "# 6) Plot the 2D embedding\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X_emb[:, 0], X_emb[:, 1], c='blue', alpha=0.7)\n",
    "plt.title(\"t-SNE of ConvLSTM Latent Space\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fic_h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
