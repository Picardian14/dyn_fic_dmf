{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.stats import gamma  # Import gamma for entropy calculation\n",
    "import fastdyn_fic_dmf as dmf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from helper_functions import filter_bold\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def calculate_gamma_entropy(node_index, rates):\n",
    "    print(f\"Processing node {node_index}\")\n",
    "    # Create arrays to store the results\n",
    "    alpha = np.zeros((rates.shape[0],))\n",
    "    loc = np.zeros((rates.shape[0],))\n",
    "    beta = np.zeros((rates.shape[0],))\n",
    "    entropy_value = np.zeros((rates.shape[0],))\n",
    "    # Average over the axis 0 (repetitions) the entropy value\n",
    "    for i in range(rates.shape[0]):\n",
    "        print(f\"Processing repetition {i}\")\n",
    "        rep_rates = rates[i]\n",
    "        # Fit a gamma distribution to the data\n",
    "        alpha[i], loc[i], beta[i] = gamma.fit(rep_rates)\n",
    "        # Calculate the entropy of the gamma distribution\n",
    "        entropy_value[i] = gamma.entropy(a=alpha[i], loc=loc[i], scale=beta[i])\n",
    "    # Average over the repetitions\n",
    "    alpha_mean = np.mean(alpha)\n",
    "    loc_mean = np.mean(loc)\n",
    "    beta_mean = np.mean(beta)\n",
    "    entropy_mean = np.mean(entropy_value)    \n",
    "    return node_index, alpha_mean, loc_mean, beta_mean, entropy_mean\n",
    "\n",
    "def compute_fcd(data, wsize, overlap, isubdiag, params):\n",
    "    T, N = data.shape\n",
    "    win_start = np.arange(0, T - params[\"wsize\"] - 1, params[\"wsize\"] - overlap)\n",
    "    nwins = len(win_start)\n",
    "    fcd = np.zeros((len(isubdiag[0]), nwins))\n",
    "    for i in range(nwins):\n",
    "        tmp = data[win_start[i]:win_start[i] + params[\"wsize\"] + 1, :]\n",
    "        cormat = np.corrcoef(tmp.T)\n",
    "        fcd[:, i] = cormat[isubdiag[0], isubdiag[1]]\n",
    "    return fcd\n",
    "\n",
    "def grid_step(args):\n",
    "    \"\"\"\n",
    "    Processes a single SEED and returns the results, including entropy per region.\n",
    "    \"\"\"\n",
    "    SEED_tuple, params, nb_steps, burnout, overlap, isubfcd, a, b = args\n",
    "    idx_SEED, SEED = SEED_tuple\n",
    "    params['seed'] = SEED\n",
    "    #print(f\"Processing Seed {SEED} (Index {idx_SEED})\")\n",
    "    \n",
    "    # Initialize a dictionary to store entropy per region\n",
    "    entropy_per_region = {}\n",
    "    \n",
    "    # Statistical FC\n",
    "    params['G'] = loadmat('../matlab/Results/stat_fc/results_awake_stat_fc.mat')['minEstimatedG_Awake']\n",
    "    params['alpha'] = loadmat('../matlab/Results/stat_fc/results_awake_stat_fc.mat')['minEstimatedY_Awake']\n",
    "    params['J'] = params['alpha'] * params['G'] * params['C'].sum(axis=0).squeeze() + 1\n",
    "    params[\"with_plasticity\"] = False\n",
    "    params[\"with_decay\"] = False\n",
    "    rates, rates_inh, bold, fic_t = dmf.run(params, nb_steps)\n",
    "    bold = bold[:, burnout:]\n",
    "    filt_bold = filter_bold(bold.T, params['flp'], params['fhp'], params['TR'])\n",
    "    stat_bold_fc = np.corrcoef(filt_bold.T)\n",
    "    \n",
    "    # Calculate entropy for Statistical FC\n",
    "    entropy_stat_fc = []\n",
    "    for node in range(params['N']):\n",
    "        node_rates = rates[:, node]\n",
    "        _, _, _, _, entropy = calculate_gamma_entropy(node, node_rates.reshape(rates.shape[0], -1))\n",
    "        entropy_stat_fc.append(entropy)\n",
    "    entropy_per_region['stat_fc'] = np.array(entropy_stat_fc)\n",
    "    \n",
    "    # Statistical FCD\n",
    "    params['G'] = loadmat('../matlab/Results/stat_fcd/results_awake_stat_fcd.mat')['minEstimatedG_Awake']\n",
    "    params['alpha'] = loadmat('../matlab/Results/stat_fcd/results_awake_stat_fcd.mat')['minEstimatedY_Awake']\n",
    "    params['J'] = params['alpha'] * params['G'] * params['C'].sum(axis=0).squeeze() + 1\n",
    "    rates, rates_inh, bold, fic_t = dmf.run(params, nb_steps)\n",
    "    bold = bold[:, burnout:]\n",
    "    filt_bold = filter_bold(bold.T, params['flp'], params['fhp'], params['TR'])\n",
    "    stat_fcd = compute_fcd(filt_bold, params[\"wsize\"], overlap, isubfcd, params)\n",
    "    stat_fcd = np.corrcoef(stat_fcd.T)\n",
    "    \n",
    "    # Calculate entropy for Statistical FCD\n",
    "    entropy_stat_fcd = []\n",
    "    for node in range(params['N']):\n",
    "        node_rates = rates[:, node]\n",
    "        _, _, _, _, entropy = calculate_gamma_entropy(node, node_rates.reshape(rates.shape[0], -1))\n",
    "        entropy_stat_fcd.append(entropy)\n",
    "    entropy_per_region['stat_fcd'] = np.array(entropy_stat_fcd)\n",
    "    \n",
    "    # Dynamic FC\n",
    "    params['G'] = loadmat('../matlab/Results/dyn_fc/results_awake_dyn_fc.mat')['minEstimatedG_Awake']\n",
    "    params['lrj'] = loadmat('../matlab/Results/dyn_fc/results_awake_dyn_fc.mat')['minEstimatedY_Awake']\n",
    "    DECAY = np.exp(a + np.log(params['lrj']) * b)\n",
    "    params['taoj'] = DECAY\n",
    "    params['alpha'] = 0.75\n",
    "    params[\"with_plasticity\"] = True\n",
    "    params[\"with_decay\"] = True\n",
    "    params['J'] = params['alpha'] * params['G'] * params['C'].sum(axis=0).squeeze() + 1\n",
    "    rates, rates_inh, bold, fic_t = dmf.run(params, nb_steps)\n",
    "    bold = bold[:, burnout:]\n",
    "    filt_bold = filter_bold(bold.T, params['flp'], params['fhp'], params['TR'])\n",
    "    dyn_bold_fc = np.corrcoef(filt_bold.T)\n",
    "    \n",
    "    # Calculate entropy for Dynamic FC\n",
    "    entropy_dyn_fc = []\n",
    "    for node in range(params['N']):\n",
    "        node_rates = rates[:, node]\n",
    "        _, _, _, _, entropy = calculate_gamma_entropy(node, node_rates.reshape(rates.shape[0], -1))\n",
    "        entropy_dyn_fc.append(entropy)\n",
    "    entropy_per_region['dyn_fc'] = np.array(entropy_dyn_fc)\n",
    "    \n",
    "    # Dynamic FCD\n",
    "    params['G'] = loadmat('../matlab/Results/dyn_fcd/results_awake_dyn_fcd.mat')['minEstimatedG_Awake']\n",
    "    params['lrj'] = loadmat('../matlab/Results/dyn_fcd/results_awake_dyn_fcd.mat')['minEstimatedY_Awake']\n",
    "    DECAY = np.exp(a + np.log(params['lrj']) * b)\n",
    "    params['taoj'] = DECAY\n",
    "    params['alpha'] = 0.75\n",
    "    params[\"with_plasticity\"] = True\n",
    "    params[\"with_decay\"] = True\n",
    "    params['J'] = params['alpha'] * params['G'] * params['C'].sum(axis=0).squeeze() + 1\n",
    "    rates, rates_inh, bold, fic_t = dmf.run(params, nb_steps)\n",
    "    bold = bold[:, burnout:]\n",
    "    filt_bold = filter_bold(bold.T, params['flp'], params['fhp'], params['TR'])\n",
    "    dyn_fcd = compute_fcd(filt_bold, params[\"wsize\"], overlap, isubfcd, params)\n",
    "    dyn_fcd = np.corrcoef(dyn_fcd.T)\n",
    "    \n",
    "    # Calculate entropy for Dynamic FCD\n",
    "    entropy_dyn_fcd = []\n",
    "    for node in range(params['N']):\n",
    "        node_rates = rates[:, node]\n",
    "        _, _, _, _, entropy = calculate_gamma_entropy(node, node_rates.reshape(rates.shape[0], -1))\n",
    "        entropy_dyn_fcd.append(entropy)\n",
    "    entropy_per_region['dyn_fcd'] = np.array(entropy_dyn_fcd)\n",
    "    \n",
    "    return {\n",
    "        'idx_SEED': idx_SEED,\n",
    "        'stat_bold_fc': stat_bold_fc,\n",
    "        'stat_fcd': stat_fcd,\n",
    "        'dyn_bold_fc': dyn_bold_fc,\n",
    "        'dyn_fcd': dyn_fcd,\n",
    "        'stat_bold': filt_bold,\n",
    "        'dyn_bold': filt_bold,\n",
    "        'entropy_stat_fc': entropy_per_region['stat_fc'],\n",
    "        'entropy_stat_fcd': entropy_per_region['stat_fcd'],\n",
    "        'entropy_dyn_fc': entropy_per_region['dyn_fc'],\n",
    "        'entropy_dyn_fcd': entropy_per_region['dyn_fcd']\n",
    "    }\n",
    "\n",
    "def integrate_results(results, N, wsize, bold_length):\n",
    "    \"\"\"\n",
    "    Integrates all results and saves the aggregated data, including entropy per region.\n",
    "    \"\"\"\n",
    "    print(\"Integrating results...\")\n",
    "    \n",
    "    SEED_count = len(results)\n",
    "    mean_fc_grid = np.zeros((2, SEED_count, N, N))\n",
    "    sim_fcds_grid = np.zeros((2, SEED_count, wsize, wsize))  # Adjust dimensions as needed\n",
    "    bold_grid = {\n",
    "        'stat_bold': np.zeros((SEED_count, bold_length, N)),\n",
    "        'dyn_bold': np.zeros((SEED_count, bold_length, N))\n",
    "    }\n",
    "    entropy_grid = {\n",
    "        'entropy_stat_fc': np.zeros((SEED_count, N)),\n",
    "        'entropy_stat_fcd': np.zeros((SEED_count, N)),\n",
    "        'entropy_dyn_fc': np.zeros((SEED_count, N)),\n",
    "        'entropy_dyn_fcd': np.zeros((SEED_count, N))\n",
    "    }\n",
    "    \n",
    "    for partial in results:\n",
    "        idx_SEED = partial['idx_SEED']\n",
    "        stat_bold_fc = partial['stat_bold_fc']\n",
    "        stat_fcd = partial['stat_fcd']\n",
    "        dyn_bold_fc = partial['dyn_bold_fc']\n",
    "        dyn_fcd = partial['dyn_fcd']\n",
    "        stat_bold = partial['stat_bold']\n",
    "        dyn_bold = partial['dyn_bold']\n",
    "        \n",
    "        entropy_stat_fc = partial['entropy_stat_fc']\n",
    "        entropy_stat_fcd = partial['entropy_stat_fcd']\n",
    "        entropy_dyn_fc = partial['entropy_dyn_fc']\n",
    "        entropy_dyn_fcd = partial['entropy_dyn_fcd']\n",
    "\n",
    "        mean_fc_grid[0, idx_SEED] = stat_bold_fc\n",
    "        sim_fcds_grid[0, idx_SEED] = stat_fcd\n",
    "        mean_fc_grid[1, idx_SEED] = dyn_bold_fc\n",
    "        sim_fcds_grid[1, idx_SEED] = dyn_fcd\n",
    "        bold_grid['stat_bold'][idx_SEED] = stat_bold\n",
    "        bold_grid['dyn_bold'][idx_SEED] = dyn_bold\n",
    "        \n",
    "        entropy_grid['entropy_stat_fc'][idx_SEED] = entropy_stat_fc\n",
    "        entropy_grid['entropy_stat_fcd'][idx_SEED] = entropy_stat_fcd\n",
    "        entropy_grid['entropy_dyn_fc'][idx_SEED] = entropy_dyn_fc\n",
    "        entropy_grid['entropy_dyn_fcd'][idx_SEED] = entropy_dyn_fcd\n",
    "\n",
    "    # Save integrated results\n",
    "    arrays_to_save = {\n",
    "        'fcs_grid': mean_fc_grid,\n",
    "        'fcds_grid': sim_fcds_grid,\n",
    "        'bold_grid_stat': bold_grid['stat_bold'],\n",
    "        'bold_grid_dyn': bold_grid['dyn_bold'],\n",
    "        'entropy_stat_fc': entropy_grid['entropy_stat_fc'],\n",
    "        'entropy_stat_fcd': entropy_grid['entropy_stat_fcd'],\n",
    "        'entropy_dyn_fc': entropy_grid['entropy_dyn_fc'],\n",
    "        'entropy_dyn_fcd': entropy_grid['entropy_dyn_fcd']\n",
    "    }\n",
    "\n",
    "    final_results_folder = \"./Results/FittedSimulations\"\n",
    "    os.makedirs(final_results_folder, exist_ok=True)\n",
    "\n",
    "    for array_name, array_data in arrays_to_save.items():\n",
    "        file_name = os.path.join(final_results_folder, f\"{array_name}.npy\")\n",
    "        np.save(file_name, array_data)\n",
    "        print(f\"Saved integrated {array_name} to {file_name}\")\n",
    "\n",
    "# Prepare parameters and data\n",
    "C = loadmat('./data/DTI_fiber_consensus_HCP.mat')['connectivity'][:200, :200]\n",
    "C = 0.2 * C / np.max(C)\n",
    "params = dmf.default_params(C=C)\n",
    "\n",
    "triu_idx = np.triu_indices(C.shape[1], 1)\n",
    "params['N'] = C.shape[0]\n",
    "isubfcd = np.triu_indices(C.shape[1], 1)\n",
    "\n",
    "# Main setup for this simulation\n",
    "params[\"return_rate\"] = True\n",
    "params[\"return_bold\"] = True\n",
    "params[\"return_fic\"] = True\n",
    "\n",
    "burnout = 7\n",
    "params[\"flp\"] = 0.01\n",
    "params[\"fhp\"] = 0.1\n",
    "params[\"wsize\"] = 30\n",
    "overlap = 29\n",
    "params['TR'] = 2\n",
    "\n",
    "T = 250\n",
    "params['dtt'] = 0.001  # Assuming 'dtt' is defined; adjust as needed\n",
    "nb_steps = int(T * params['TR'] / params['dtt'])\n",
    "win_start = np.arange(0, T - burnout - params[\"wsize\"], params[\"wsize\"] - overlap)\n",
    "nwins = len(win_start)\n",
    "nints = len(isubfcd[0])\n",
    "\n",
    "fit_res = np.load(\"./data/fit_res_3-44.npy\", allow_pickle=True)\n",
    "b = fit_res[0]  # First element is the slope\n",
    "a = fit_res[1]\n",
    "\n",
    "SEED_range = list(range(1, 101))  # SEEDs from 1 to 100\n",
    "\n",
    "# Adjust the number of cores based on your local machine\n",
    "# For example, use os.cpu_count() to automatically detect\n",
    "NUM_CORES = min(24, os.cpu_count())  # Use up to 24 cores or the maximum available\n",
    "\n",
    "OBJ_RATE = 3.44\n",
    "params['obj_rate'] = OBJ_RATE\n",
    "\n",
    "# Prepare all SEEDs for processing\n",
    "task_seeds = SEED_range\n",
    "task_indices = list(range(len(task_seeds)))\n",
    "task_args = [((idx_SEED, SEED), params.copy(), nb_steps, burnout, overlap, isubfcd, a, b)\n",
    "            for idx_SEED, SEED in zip(task_indices, task_seeds)]\n",
    "\n",
    "# Process SEEDs using multiprocessing Pool\n",
    "print(f\"Starting processing of {len(task_seeds)} SEEDs using {NUM_CORES} cores...\")\n",
    "with Pool(processes=NUM_CORES) as pool:\n",
    "    results = pool.map(grid_step, task_args)\n",
    "\n",
    "#return idx_SEED, mean_fc, sim_fcds,mean_firing_rates, std_firing_rates\n",
    "for results in results_list:\n",
    "    idx_SEED = results[0]        \n",
    "    stat_bold_fc = results[1]\n",
    "    stat_fcd = results[2] \n",
    "    dyn_bold_fc = results[3]  \n",
    "    dyn_fcd = results[4]\n",
    "    stat_bold = results[5]\n",
    "    dyn_bold = results[6]\n",
    "    \n",
    "    mean_fc_grid[0,idx_SEED] = stat_bold_fc\n",
    "    sim_fcds_grid[0,idx_SEED] = stat_fcd\n",
    "    mean_fc_grid[1,idx_SEED] = dyn_bold_fc\n",
    "    sim_fcds_grid[1,idx_SEED] = dyn_fcd\n",
    "    bold_grid[0,idx_SEED] = stat_bold\n",
    "    bold_grid[1,idx_SEED] = dyn_bold\n",
    "    \n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Assuming these arrays are already populated with data\n",
    "\n",
    "arrays_to_save = {\n",
    "    'fcs_grid': mean_fc_grid,\n",
    "    'fcds_grid': sim_fcds_grid,\n",
    "    'bold_grid': bold_grid,\n",
    "}\n",
    "\n",
    "results_folder = \"./Results/FittedSimulations\"\n",
    "\n",
    "# Save\n",
    "for array_name, array_data in arrays_to_save.items():\n",
    "    file_name = os.path.join(results_folder, f\"{array_name}.npy\")\n",
    "    np.save(file_name, array_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "arrays_to_save = ['fcs_grid',\n",
    "    'fcds_grid',]\n",
    "    #'bold_grid']\n",
    "\n",
    "results_folder = \"./Results/FittedSimulations\"\n",
    "results = {}\n",
    "for array_name in arrays_to_save:\n",
    "    file_name = os.path.join(results_folder, f\"{array_name}.npy\")\n",
    "    results[array_name] = np.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debuging bold"
     ]
    }
   ],
   "source": [
    "results = loadmat('/network/iss/home/ivan.mindlin/dyn_fic_dmf/matlab/Results/dyn_fcd/results_awake_dyn_fcd.mat')\n",
    "params['G'] = 2.1#results['minEstimatedG_Awake'][0][0]\n",
    "params['lrj'] = 10#results['minEstimatedY_Awake'][0][0]\n",
    "DECAY = np.exp(a+np.log(params['lrj'])*b)\n",
    "params['taoj'] = DECAY \n",
    "params['J'] = 0.75 * params['G'] * params['C'].sum(axis=0).squeeze() + 1    \n",
    "params[\"with_plasticity\"] = True\n",
    "params[\"with_decay\"] = True  \n",
    "params['seed'] = 1\n",
    "# Run the simulation\n",
    "rates, rates_inh, bold, fic_t = dmf.run(params, nb_steps)         \n",
    "#bold = bold[:, burnout:]\n",
    "#filt_bold = filter_bold(bold.T, params['flp'], params['fhp'], params['TR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a pickle with the results of the simulation and the params\n",
    "import pickle\n",
    "with open('Results/debug_python_compiled.pkl', 'wb') as f:\n",
    "    pickle.dump({'rates': rates, 'rates_inh': rates_inh, 'bold': bold, 'params': params}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_test = loadmat('/network/iss/home/ivan.mindlin/dyn_fic_dmf/matlab/Results/debug_matlab_recompiled_nonan.mat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
