{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "import fastdyn_fic_dmf as dmf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Fetch default parameters\n",
    "import tracemalloc\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import zscore, pearsonr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "import os\n",
    "import mat73\n",
    "#from mne.time_frequency import psd_array_multitaper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Custom modules (as in your snippet)\n",
    "import fastdyn_fic_dmf as dmf\n",
    "from helper_functions import filter_bold\n",
    "\n",
    "################################################################################\n",
    "# Helper functions\n",
    "################################################################################\n",
    "\n",
    "def compute_fc(data):\n",
    "    \"\"\"\n",
    "    Compute FC by correlating BOLD (or rate) time series.\n",
    "    data shape: (time, nodes).\n",
    "    Returns an (N x N) correlation matrix.\n",
    "    \"\"\"\n",
    "    return np.corrcoef(data.T)  # shape [N, N]\n",
    "\n",
    "def compute_fcd(data, wsize, overlap, isubdiag):\n",
    "    \"\"\"\n",
    "    Compute FCD by sliding a window of length 'wsize' with 'overlap' into 'data'.\n",
    "    \n",
    "    data shape: (time, nodes).\n",
    "    wsize, overlap: integer time points.\n",
    "    isubdiag: np.triu_indices(N, 1) or similar.\n",
    "\n",
    "    Returns a 2D array:\n",
    "        shape [num_windows, number_of_corr_pairs]\n",
    "    where number_of_corr_pairs = len(isubdiag[0]).\n",
    "    \"\"\"\n",
    "    T, N = data.shape\n",
    "    step = wsize - overlap\n",
    "    win_starts = np.arange(0, T - wsize + 1, step)\n",
    "    \n",
    "    fcd_mat = []\n",
    "    for start in win_starts:\n",
    "        window_data = data[start:start + wsize, :]\n",
    "        cormat = np.corrcoef(window_data.T)\n",
    "        fcd_mat.append(cormat[isubdiag])\n",
    "    fcd_mat = np.corrcoef(np.array(fcd_mat))  # shape [num_windows, n_subdiag]\n",
    "    return fcd_mat  # shape [num_windows, n_subdiag]\n",
    "\n",
    "\n",
    "\n",
    "def simulate_one_seed(args):\n",
    "    \"\"\"\n",
    "    Run the DMF model for a single seed, given LR and G (plus a,b for DECAY),\n",
    "    and return (FC, FCD).\n",
    "    \"\"\"\n",
    "    (params_base, nb_steps, burnout, wsize, overlap, seed_id, a, b, isubdiag) = args\n",
    "\n",
    "    # Copy base params so we don't mutate them\n",
    "    params = params_base.copy()\n",
    "    params['seed'] = seed_id\n",
    "    \n",
    "    # Compute DECAY from a, b, lrj\n",
    "    DECAY = np.exp(a + np.log(params['lrj']) * b)\n",
    "    params['taoj'] = DECAY\n",
    "    \n",
    "    # Because we want to see plastic changes\n",
    "    params[\"with_plasticity\"] = True\n",
    "    params[\"with_decay\"]      = True\n",
    "    \n",
    "    # (Re)compute 'J' after setting alpha, G, etc.\n",
    "    # If alpha is always 0.75 or you prefer a different logic, do it here:\n",
    "    params['alpha'] = 0.75\n",
    "    params['J'] = params['alpha'] * params['G'] * params['C'].sum(axis=0).squeeze() + 1\n",
    "\n",
    "    # Run DMF\n",
    "    # Returns: (rates, bold, fic, etc.) -- adjust if your function differs\n",
    "    _, _, bold, _ = dmf.run(params, nb_steps)\n",
    "    \n",
    "    # Burn out the initial transients\n",
    "    bold_post = bold[:, burnout:]  # shape [N, T-burnout]\n",
    "    \n",
    "    # If we need to filter the BOLD, do it here\n",
    "    # Convert to shape [time, nodes] for correlation\n",
    "    bold_post = bold_post.T  # shape [T-burnout, N]\n",
    "    bold_filt = filter_bold(bold_post, params['flp'], params['fhp'], params['TR'])\n",
    "\n",
    "    # Compute FC\n",
    "    fc_seed = compute_fc(bold_filt)  # shape [N, N]\n",
    "\n",
    "    # Compute FCD\n",
    "    fcd_seed = compute_fcd(bold_filt, wsize, overlap, isubdiag)  \n",
    "    # shape [num_windows, n_subdiag]\n",
    "\n",
    "    return fc_seed, fcd_seed\n",
    "\n",
    "def grid_step(args):\n",
    "    \"\"\"\n",
    "    Process a single (LR, G) pair by running multiple seeds.\n",
    "    Return:\n",
    "      {\n",
    "        'idx_lr': idx_lr,\n",
    "        'idx_g':  idx_g,\n",
    "        'FC_avg':  (N x N),\n",
    "        'FCD_stacked': (n_seeds x num_windows x n_subdiag)\n",
    "      }\n",
    "    \"\"\"\n",
    "    (idx_lr, LR_val, idx_g, G_val,\n",
    "     params, nb_steps, burnout, wsize, overlap, n_seeds,\n",
    "     a, b, isubdiag) = args\n",
    "\n",
    "    # Set the LR & G in the param dictionary\n",
    "    params['lrj'] = LR_val\n",
    "    params['G']   = G_val\n",
    "    \n",
    "    N = params['N']\n",
    "\n",
    "    # We'll sum FCs to get an average later\n",
    "    fc_sum = np.zeros((N, N), dtype=np.float32)\n",
    "    fcd_list = []\n",
    "\n",
    "    # Prepare a local list of seeds\n",
    "    # Example: we might do seeds = range(n_seeds), or something more elaborate\n",
    "    # For demonstration, we just do seeds 0..(n_seeds-1)\n",
    "    seed_list = range(n_seeds)\n",
    "    \n",
    "    # Build arguments for simulate_one_seed\n",
    "    simulate_args = []\n",
    "    for seed_id in seed_list:\n",
    "        # Some unique seed scheme:\n",
    "        # e.g. seed_in = seed_id + 1000 * idx_lr + 10000 * idx_g\n",
    "        seed_in = seed_id + idx_lr + 2 * idx_g\n",
    "        simulate_args.append((\n",
    "            params,           # base param\n",
    "            nb_steps,\n",
    "            burnout,\n",
    "            wsize,\n",
    "            overlap,\n",
    "            seed_in,\n",
    "            a,\n",
    "            b,\n",
    "            isubdiag\n",
    "        ))\n",
    "    \n",
    "    # Run seeds in parallel\n",
    "    NWORKERS = 16\n",
    "    fcs = []\n",
    "    with Pool(NWORKERS) as local_pool:\n",
    "        results = local_pool.map(simulate_one_seed, simulate_args)\n",
    "    # Kill Pool\n",
    "    local_pool.close()\n",
    "\n",
    "    # Aggregate\n",
    "    for fc_seed, fcd_seed in results:\n",
    "        fc_sum += fc_seed\n",
    "        fcd_list.append(fcd_seed)\n",
    "        fcs.append(fc_seed)\n",
    "\n",
    "    # Average FC\n",
    "    \n",
    "    fc_avg = fc_sum / n_seeds\n",
    "    \n",
    "    # Stack FCD => shape [n_seeds, num_windows, n_subdiag]\n",
    "    fcd_stacked = np.stack(fcd_list, axis=0)\n",
    "\n",
    "    return {\n",
    "        'idx_lr': idx_lr,\n",
    "        'idx_g':  idx_g,\n",
    "        'FC_avg': fc_avg,\n",
    "        'FCD_stacked': fcd_stacked,\n",
    "        'fcs': fcs\n",
    "    }\n",
    "\n",
    "################################################################################\n",
    "# Integration of partial results\n",
    "################################################################################\n",
    "\n",
    "def integrate_results(total_tasks, results_folder,\n",
    "                      nLR, nG, n_seeds, output_folder):\n",
    "    \"\"\"\n",
    "    Loads partial results from partial_result_0..(total_tasks-1).npy\n",
    "    and constructs final arrays:\n",
    "      FC_grid:  (nLR, nG, N, N)\n",
    "      FCD_grid: (nLR, nG, n_seeds, num_windows, n_subdiag)\n",
    "\n",
    "    Then saves them to output_folder.\n",
    "    \"\"\"\n",
    "    print(\"[integrate_results] Integrating partial results...\")\n",
    "\n",
    "    FC_grid = None\n",
    "    FCD_grid = None\n",
    "    loaded_something = False\n",
    "\n",
    "    for task_idx in range(total_tasks):\n",
    "        partial_file = os.path.join(results_folder, f\"partial_result_{task_idx}.npy\")\n",
    "        if not os.path.exists(partial_file):\n",
    "            print(f\"  [Warning] partial file not found: {partial_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Each partial is a list of dicts: { 'idx_lr', 'idx_g', 'FC_avg', 'FCD_stacked' }\n",
    "        partial_data = np.load(partial_file, allow_pickle=True)\n",
    "        \n",
    "        for item in partial_data:\n",
    "            idx_lr = item['idx_lr']\n",
    "            idx_g  = item['idx_g']\n",
    "            fc_avg = item['FC_avg']       # shape [N, N]\n",
    "            fcd_st = item['FCD_stacked']  # shape [n_seeds, num_windows, n_subdiag]\n",
    "\n",
    "            if not loaded_something:\n",
    "                N = fc_avg.shape[0]\n",
    "                num_windows = fcd_st.shape[1]\n",
    "                n_subdiag  = fcd_st.shape[2]\n",
    "\n",
    "                FC_grid  = np.zeros((nLR, nG, N, N), dtype=np.float32)\n",
    "                FCD_grid = np.zeros((nLR, nG, n_seeds, num_windows, num_windows), dtype=np.float32)\n",
    "                loaded_something = True\n",
    "\n",
    "            FC_grid[idx_lr, idx_g]  = fc_avg\n",
    "            FCD_grid[idx_lr, idx_g] = fcd_st\n",
    "\n",
    "    # Save final results\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    if FC_grid is not None:\n",
    "        np.save(os.path.join(output_folder, \"FC_grid.npy\"), FC_grid)\n",
    "        print(\"[integrate_results] Saved FC_grid\")\n",
    "    if FCD_grid is not None:\n",
    "        np.save(os.path.join(output_folder, \"FCD_grid.npy\"), FCD_grid)\n",
    "        print(\"[integrate_results] Saved FCD_grid\")\n",
    "\n",
    "    print(\"[integrate_results] Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tasks = 8\n",
    "task_idx = 0\n",
    "\n",
    "# Load structural connectivity\n",
    "C = loadmat('./data/DTI_fiber_consensus_HCP.mat')['connectivity'][:200,:200]\n",
    "C = 0.2 * C / np.max(C)\n",
    "\n",
    "# Base DMF params\n",
    "params = dmf.default_params(C=C)\n",
    "params['N'] = C.shape[0]\n",
    "N = params['N']\n",
    "\n",
    "# Filtering params (adapt to your usage)\n",
    "params[\"flp\"] = 0.01\n",
    "params[\"fhp\"] = 0.1\n",
    "params[\"TR\"]  = 2\n",
    "\n",
    "# For windowed FCD\n",
    "wsize   = 30\n",
    "overlap = 29\n",
    "\n",
    "# Burnout in time points (or directly # of samples)\n",
    "burnout = 7  # if your run uses 1 step = 1 ms, might be burnout * 1000\n",
    "                # but adapt to how your model is defined\n",
    "\n",
    "# Total simulation time in TRs:\n",
    "T = 250\n",
    "# We assume dtt from your snippet:\n",
    "params['dtt'] = 0.001\n",
    "nb_steps = int(T * params[\"TR\"] / params[\"dtt\"])\n",
    "\n",
    "# Indices for the upper triangular part (for FC or FCD)\n",
    "isubdiag = np.triu_indices(N, 1)\n",
    "\n",
    "# Load slope and intercept for DECAY\n",
    "fit_res  = np.load(\"./data/fit_res_3-44.npy\", allow_pickle=True)\n",
    "b = fit_res[0]  # slope\n",
    "a = fit_res[1]  # intercept\n",
    "\n",
    "# Grid definitions\n",
    "nLR = 110\n",
    "LR_range = np.logspace(0, 3, nLR)   # from 1 to 1000\n",
    "nG  = 100\n",
    "G_range = np.linspace(0.1, 16, nG)  # from 0.1 to 16\n",
    "\n",
    "# Seeds per (LR, G)\n",
    "n_seeds = 16\n",
    "\n",
    "# Build the entire list of (LR, G) pairs\n",
    "all_args = []\n",
    "for idx_lr, LR_val in enumerate(LR_range):\n",
    "    for idx_g, G_val in enumerate(G_range):\n",
    "        # We pass everything needed, including a,b\n",
    "        all_args.append((\n",
    "            idx_lr, LR_val,\n",
    "            idx_g,  G_val,\n",
    "            params.copy(),\n",
    "            nb_steps,\n",
    "            burnout,\n",
    "            wsize,\n",
    "            overlap,\n",
    "            n_seeds,\n",
    "            a, b,\n",
    "            isubdiag\n",
    "        ))\n",
    "\n",
    "# Distribute (LR, G) pairs among tasks\n",
    "total_pairs = len(all_args)\n",
    "chunk_size = math.ceil(total_pairs / total_tasks)\n",
    "start_idx = task_idx * chunk_size\n",
    "end_idx   = min(start_idx + chunk_size, total_pairs)\n",
    "task_args = all_args[start_idx:end_idx]\n",
    "\n",
    "# Folder for partial results\n",
    "partial_results_folder = \"./Results/Partial_Grid_LR_G\"\n",
    "os.makedirs(partial_results_folder, exist_ok=True)\n",
    "\n",
    "# Each task processes its chunk of (LR, G) pairs in SERIAL,\n",
    "# but seeds are parallelized in grid_step()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = task_args[513]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(idx_lr, LR_val, idx_g, G_val,\n",
    "    params, nb_steps, burnout, wsize, overlap, n_seeds,\n",
    "    a, b, isubdiag) = args\n",
    "\n",
    "# Set the LR & G in the param dictionary\n",
    "params['lrj'] = LR_val\n",
    "params['G']   = G_val\n",
    "\n",
    "N = params['N']\n",
    "\n",
    "# We'll sum FCs to get an average later\n",
    "fc_sum = np.zeros((N, N), dtype=np.float32)\n",
    "fcd_list = []\n",
    "\n",
    "# Prepare a local list of seeds\n",
    "# Example: we might do seeds = range(n_seeds), or something more elaborate\n",
    "# For demonstration, we just do seeds 0..(n_seeds-1)\n",
    "seed_list = range(n_seeds)\n",
    "\n",
    "# Build arguments for simulate_one_seed\n",
    "simulate_args = []\n",
    "for seed_id in seed_list:\n",
    "    # Some unique seed scheme:\n",
    "    # e.g. seed_in = seed_id + 1000 * idx_lr + 10000 * idx_g\n",
    "    seed_in = seed_id + idx_lr + 2 * idx_g\n",
    "    simulate_args.append((\n",
    "        params,           # base param\n",
    "        nb_steps,\n",
    "        burnout,\n",
    "        wsize,\n",
    "        overlap,\n",
    "        seed_in,\n",
    "        a,\n",
    "        b,\n",
    "        isubdiag\n",
    "    ))\n",
    "\n",
    "# Run seeds in parallel\n",
    "NWORKERS = 16\n",
    "fcs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debuging bold"
     ]
    }
   ],
   "source": [
    "one_res = simulate_one_seed(simulate_args[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 214)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_res[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging boldDebuging bold"
     ]
    }
   ],
   "source": [
    "\n",
    "results_list = []\n",
    "for args in [task_args[13]]:\n",
    "    res = grid_step(args)\n",
    "    results_list.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastdyn_fic_dmf as dmf\n",
    "\n",
    "def compute_fcd(data, wsize, overlap, isubdiag, params):\n",
    "    T, N = data.shape\n",
    "    win_start = np.arange(0, T - params[\"wsize\"] - 1, params[\"wsize\"] - overlap)\n",
    "    nwins = len(win_start)\n",
    "    fcd = np.zeros((len(isubdiag[0]), nwins))\n",
    "    for i in range(nwins):\n",
    "        tmp = data[win_start[i]:win_start[i] + params[\"wsize\"] + 1, :]\n",
    "        cormat = np.corrcoef(tmp.T)\n",
    "        fcd[:, i] = cormat[isubdiag[0], isubdiag[1]]\n",
    "    return fcd\n",
    "\n",
    "C = loadmat('./data/DTI_fiber_consensus_HCP.mat')['connectivity'][:200, :200]\n",
    "C = 0.2 * C / np.max(C)\n",
    "params = dmf.default_params(C=C)\n",
    "params['N'] = C.shape[0]\n",
    "isubfcd = np.triu_indices(C.shape[1], 1)\n",
    "burnout = 7\n",
    "params[\"wsize\"] = 30\n",
    "overlap = 29\n",
    "params['TR'] = 2\n",
    "T = 250\n",
    "params['dtt'] = 0.001  # Assuming 'dtt' is defined; adjust as needed\n",
    "nb_steps = int(T * params['TR'] / params['dtt'])\n",
    "win_start = np.arange(0, T - burnout - params[\"wsize\"], params[\"wsize\"] - overlap)\n",
    "nwins = len(win_start)\n",
    "nints = len(isubfcd[0])\n",
    "\n",
    "emp_data = mat73.loadmat('data/BOLD_timeseries_Awake.mat')\n",
    "emp_data = np.squeeze(np.array(emp_data['BOLD_timeseries_Awake']))[:,:200,:]\n",
    "emp_data = emp_data[:,:,burnout:]\n",
    "\n",
    "\n",
    "emp_fcds = []\n",
    "for sub in range(emp_data.shape[0]):\n",
    "    fcds = compute_fcd(emp_data[sub, :, :].T, params[\"wsize\"], overlap, isubfcd, params)\n",
    "    upp_tr_fcd = np.corrcoef(fcds.T)[np.triu_indices(nwins-1, 1)]\n",
    "    emp_fcds.append(upp_tr_fcd)\n",
    "\n",
    "emp_fc = np.mean(np.array([np.corrcoef(emp_data[sub, :, :]) for sub in range(emp_data.shape[0])]), axis=0)\n",
    "emp_fcds = np.hstack((emp_fcds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upper_triangular_flat(mat):\n",
    "    \"\"\"\n",
    "    Return the flattened upper triangular (off-diagonal) elements of a square matrix.\n",
    "    \"\"\"\n",
    "    # np.triu_indices excludes the diagonal if we pass k=1\n",
    "    triu_idx = np.triu_indices(mat.shape[0], k=1)\n",
    "    return mat[triu_idx]\n",
    "\n",
    "def fc_fit_metric(emp_fc, sim_fc):\n",
    "    \"\"\"\n",
    "    Compute 1 - Pearson correlation for the upper-triangular (off-diagonal) entries.\n",
    "    \"\"\"\n",
    "    emp_vals = upper_triangular_flat(emp_fc)\n",
    "    sim_vals = upper_triangular_flat(sim_fc)\n",
    "    # Handle potential zero-variance corner cases:\n",
    "    if np.std(emp_vals) == 0 or np.std(sim_vals) == 0:\n",
    "        return 1.0  # If there's no variance, treat as worst-case mismatch\n",
    "    \n",
    "    corr, _ = pearsonr(emp_vals, sim_vals)\n",
    "    return 1.0 - corr\n",
    "\n",
    "def fcd_fit_metric(emp_fcds, sim_fcd):\n",
    "    \"\"\"\n",
    "    Compute the average KS distance between the simulated FCD distribution\n",
    "    and each subject's empirical FCD distribution, using only the\n",
    "    upper triangular (off-diagonal) entries.\n",
    "    \"\"\"\n",
    "    sim_vals = upper_triangular_flat(sim_fcd)\n",
    "            \n",
    "    # Compute KS distance\n",
    "    D, _ = ks_2samp(emp_fcds, sim_vals)        \n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_fcds = []\n",
    "for fcd in res['FCD_stacked']:\n",
    "    flattened_fcds.append(upper_triangular_flat(fcd))\n",
    "flattened_fcds = np.hstack(flattened_fcds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48010986517109255\n"
     ]
    }
   ],
   "source": [
    "print(ks_2samp(emp_fcds, flattened_fcds)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4938584249467614\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(fcd_fit_metric(emp_fcds, res['FCD_stacked'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "for arg_tuple in task_args:\n",
    "    # grid_step() itself parallelizes across seeds\n",
    "    result = grid_step(arg_tuple)\n",
    "    results.append(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
