{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "import fastdyn_fic_dmf as dmf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Fetch default parameters\n",
    "import tracemalloc\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import zscore, pearsonr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "\n",
    "def compute_fcd(data, wsize, overlap, isubdiag):\n",
    "    T, N = data.shape\n",
    "    win_start = np.arange(0, T - wsize - 1, wsize - overlap)\n",
    "    nwins = len(win_start)\n",
    "    fcd = np.zeros((len(isubdiag[0]), nwins))\n",
    "    print(fcd.shape)\n",
    "    print(data.shape)\n",
    "    print((data[win_start[2]:win_start[2] + wsize + 1, :]).shape)\n",
    "    for i in range(nwins):\n",
    "        tmp = data[win_start[i]:win_start[i] + wsize + 1, :]\n",
    "        cormat = np.corrcoef(tmp.T)\n",
    "        fcd[:, i] = cormat[isubdiag[0],isubdiag[1]]\n",
    "    return fcd\n",
    "\n",
    "\n",
    "nb_steps = 100000\n",
    "C = loadmat('../SC_and_5ht2a_receptors.mat')['sc90']\n",
    "# Load coefficients to estimte Decay with LR\n",
    "coeffs = loadmat('./data/LinearFitCoefficients.mat')\n",
    "a = coeffs['a'][0][0]\n",
    "b = coeffs['b'][0][0]\n",
    "C = 0.2*C/np.max(C)\n",
    "triu_idx = np.triu_indices(C.shape[1],1)\n",
    "brunout = 5\n",
    "params = dmf.default_params(C=C)\n",
    "params['N'] = C.shape[0]\n",
    "params['seed'] = 2\n",
    "sampling_freq = 10000\n",
    "G_max = 25\n",
    "DECAY_max = 60000\n",
    "OBJ_RATE_max = 15\n",
    "G_step = 0.5\n",
    "DECAY_step = 20000\n",
    "OBJ_RATE_step = 3\n",
    "G_range = np.arange(0,G_max,G_step)\n",
    "LR_range = np.logspace(0, 3,100)\n",
    "\n",
    "#G_range = [1,2]\n",
    "#LR_range = [10,200]\n",
    "# Define the number of cores to use\n",
    "NUM_CORES = 16\n",
    "peak_autocorrelation_grid = np.zeros((len(G_range),len(LR_range)))\n",
    "peak_time_grid = np.zeros((len(G_range),len(LR_range)))\n",
    "power_grid = np.zeros((len(G_range),len(LR_range), params['N'],951)) # Hardcoded number of frequencies with the given parameters of filtering\n",
    "std_slow_grid = np.zeros((len(G_range),len(LR_range)))\n",
    "corr_to_sc_grid = np.zeros((len(G_range),len(LR_range)))\n",
    "homeostatic_fittness_grid = np.zeros((len(G_range),len(LR_range)))\n",
    "rates_grid = np.zeros((len(G_range),len(LR_range),params['N']))\n",
    "fic_t_grid = np.zeros((len(G_range),len(LR_range),params['N']))\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "def get_peak_and_ms(rates):\n",
    "    \"\"\"Get the value of the first peak from the autocorrealtion of the average firing rates\"\"\"\n",
    "    signal = np.mean(rates, axis=0)\n",
    "    signal -= np.mean(signal)\n",
    "\n",
    "    # Calculate autocorrelation function\n",
    "    autocorr = np.correlate(signal, signal, mode='full')\n",
    "\n",
    "    # Normalize the autocorrelation function\n",
    "    autocorr = autocorr / np.var(signal) / len(signal)\n",
    "    autocorr = autocorr[len(signal)-1:]\n",
    "    peaks, _ = find_peaks(autocorr, height=(0.2,0.8), prominence=0.2)\n",
    "    if peaks.size==0:\n",
    "        autocorr_value = 0\n",
    "        time = 0\n",
    "    else:\n",
    "        autocorr_value = autocorr[peaks[0]]\n",
    "        time = peaks[0]\n",
    "    return autocorr_value,time\n",
    "\n",
    "\n",
    "def grid_step(args):\n",
    "    G_tuple, LR_tuple = args\n",
    "    idx_LR,LR = LR_tuple[0],LR_tuple[1]\n",
    "    idx_G,G = G_tuple[0],G_tuple[1]\n",
    "    DECAY = np.exp(a+np.log(LR)*b)\n",
    "    OBJ_RATE = 3.44\n",
    "    print(f\"Running - G:{G} / DECAY:{DECAY} / OBJ_RATE:{OBJ_RATE} / LR:{LR} \\n\")\n",
    "    with_decay = DECAY>0\n",
    "    params['lrj'] = LR\n",
    "    params['G'] = G\n",
    "    # Using heuristic linear rule \n",
    "    params['taoj'] = DECAY if with_decay else 10 # If 0 it means no plasticity at all. We put some value so it does not crash\n",
    "    params['obj_rate'] = OBJ_RATE\n",
    "    #params['taoj'] = 210000\n",
    "    params['J'] = 0.75*params['G']*params['C'].sum(axis=0).squeeze() + 1\n",
    "    rates, rates_inh, _, fic_t = dmf.run(params, nb_steps,\n",
    "                                            return_rate=True, return_bold=False, return_fic=True, \n",
    "                                            with_decay=with_decay, with_plasticity=True)        \n",
    "    rates = rates[:, np.ceil(brunout * 1000).astype(int):]\n",
    "    rates_inh = rates_inh[:, np.ceil(brunout * 1000).astype(int):]\n",
    "    fic_t = fic_t[:, np.ceil(brunout * 1000).astype(int):]\n",
    "    rates_fc = np.corrcoef(rates)\n",
    "    power_spectrum,frequencies = psd_array_multitaper(rates, verbose=False,sfreq=sampling_freq, fmin=0, fmax=100,bandwidth=32*(sampling_freq/rates.shape[1]))\n",
    "    peak_autocorrelation,peak_time = get_peak_and_ms(rates)\n",
    "    corr_to_sc = pearsonr(rates_fc[triu_idx[0],triu_idx[1]], C[triu_idx[0],triu_idx[1]])[0]\n",
    "    \n",
    "    homeostatic_fittness =  OBJ_RATE - np.mean(rates)  \n",
    "    return idx_G,idx_LR, peak_autocorrelation,peak_time,corr_to_sc ,homeostatic_fittness,np.mean(rates,axis=1),np.mean(fic_t,axis=1), power_spectrum\n",
    "\n",
    "\n",
    "\n",
    "from multiprocessing import Pool,Manager\n",
    "\n",
    "\n",
    "# Define the number of cores to use\n",
    "\n",
    "# Create a list of argument tuples for the nested loop function\n",
    "args_list = [((idx_G,G), (idx_LR,LR))\n",
    "             for idx_G,G in enumerate(G_range)             \n",
    "             for idx_LR,LR in enumerate(LR_range)]\n",
    "\n",
    "manager = Manager()\n",
    "results_list = manager.list()\n",
    "# Create a pool of worker processes\n",
    "with Pool(processes=NUM_CORES) as pool:\n",
    "    # Map the nested loop function to the argument list across multiple processes\n",
    "    results_list.extend(pool.map(grid_step, args_list))\n",
    "\n",
    "\n",
    "\n",
    "for results in results_list:\n",
    "    idx_G = results[0]    \n",
    "    idx_LR = results[1]\n",
    "    peak_autocorrelation = results[2]\n",
    "    peak_time = results[3]    \n",
    "    corr_to_sc = results[4]\n",
    "    homeostatic_fittness = results[5]\n",
    "    rates = results[6]\n",
    "    fic_t = results[7]\n",
    "    power_spectrum = results[8]\n",
    "    peak_autocorrelation_grid[idx_G,idx_LR] = peak_autocorrelation\n",
    "    peak_time_grid[idx_G,idx_LR] = peak_time    \n",
    "    power_grid[idx_G, idx_LR] = power_spectrum\n",
    "    corr_to_sc_grid[idx_G,idx_LR] = corr_to_sc\n",
    "    homeostatic_fittness_grid[idx_G,idx_LR] = homeostatic_fittness\n",
    "    rates_grid[idx_G,idx_LR,:] = rates\n",
    "    fic_t_grid[idx_G,idx_LR,:] = fic_t\n",
    "\n",
    "\n",
    "    import os\n",
    "\n",
    "# Assuming these arrays are already populated with data\n",
    "\n",
    "arrays_to_save = {\n",
    "    'peak_autocorrelation_grid': peak_autocorrelation_grid,\n",
    "    'peak_time_grid': peak_time_grid,\n",
    "    'power_grid': power_grid,\n",
    "    'corr_to_sc_grid': corr_to_sc_grid,\n",
    "    'homeostatic_fittness_grid': homeostatic_fittness_grid,\n",
    "    'rates_grid': rates_grid,\n",
    "    'fic_t_grid': fic_t_grid\n",
    "}\n",
    "\n",
    "results_folder = \"./Results/G_LR\"\n",
    "\n",
    "# Save\n",
    "for array_name, array_data in arrays_to_save.items():\n",
    "    file_name = os.path.join(results_folder, f\"{array_name}.npy\")\n",
    "    np.save(file_name, array_data)\n",
    "\n",
    "\n",
    "# Create subplots\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Heatmap for peak_time_grid\n",
    "im1 = axes[0].imshow(peak_time_grid, cmap='viridis', origin='lower', aspect='auto', vmax=2000)\n",
    "axes[0].set_title('Heatmap for peak_time_grid')\n",
    "axes[0].set_xlabel('LR')\n",
    "axes[0].set_ylabel('G')\n",
    "# Set logarithmic tick labels for LR\n",
    "log_labels = ['' for _ in range(len(LR_range))]\n",
    "log_labels[0] = 1\n",
    "log_labels[33] = 10\n",
    "log_labels[66] = 100\n",
    "log_labels[99] = 1000\n",
    "axes[0].set_xticks(range(len(LR_range)))\n",
    "axes[0].set_xticklabels(log_labels)\n",
    "axes[0].set_yticks(range(0,50,5))\n",
    "axes[0].set_yticklabels(G_range[range(0,50,5)])\n",
    "plt.colorbar(im1, ax=axes[0], label='Values')\n",
    "# Heatmap for peak_autocorrelation_grid\n",
    "im2 = axes[1].imshow(peak_autocorrelation_grid, cmap='viridis', origin='lower', aspect='auto')\n",
    "axes[1].set_title('Heatmap for peak_autocorrelation_grid')\n",
    "axes[1].set_xlabel('LR')\n",
    "axes[1].set_ylabel('G')\n",
    "axes[1].set_xticks(range(len(LR_range)))\n",
    "axes[1].set_xticklabels(log_labels)\n",
    "axes[1].set_yticks(range(0,50,5))\n",
    "axes[1].set_yticklabels(G_range[range(0,50,5)])\n",
    "plt.colorbar(im2, ax=axes[1], label='Values')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
