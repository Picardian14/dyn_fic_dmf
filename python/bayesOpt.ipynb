{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 70,
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
   "metadata": {},
   "outputs": [],
   "source": [
    "#from helper_funcs import bayes_step\n",
    "import fastdyn_fic_dmf as dmf\n",
    "from mango import Tuner, scheduler\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "N_JOBS = 2\n",
    "\n",
    "\n",
    "@scheduler.serial\n",
    "def bayes_step_withG(G, DECAY, LR):\n",
    "    OBJ_RATE = 3.44\n",
    "    sampling_freq = 10000\n",
    "    nb_steps = 100000\n",
    "    C = loadmat('../SC_and_5ht2a_receptors.mat')['sc90']\n",
    "    C = 0.2*C/np.max(C)\n",
    "    triu_idx = np.triu_indices(C.shape[1],1)\n",
    "    brunout = 5\n",
    "    params = dmf.default_params(C=C)\n",
    "    params['N'] = C.shape[0]\n",
    "    #print(f\"Running - G:{G} / DECAY:{DECAY} / OBJ_RATE:{OBJ_RATE} / LR:{LR} \\n\")\n",
    "    with_decay = DECAY>0\n",
    "    params['lrj'] = LR\n",
    "    params['G'] = G\n",
    "    params['taoj'] = DECAY if with_decay else 10 # If 0 it means no plasticity at all. We put some value so it does not crash\n",
    "    params['obj_rate'] = OBJ_RATE\n",
    "    #params['taoj'] = 210000\n",
    "    params['J'] = 0.75*params['G']*params['C'].sum(axis=0).squeeze() + 1\n",
    "    rates, rates_inh, _, fic_t = dmf.run(params, nb_steps,\n",
    "                                            return_rate=True, return_bold=False, return_fic=True, \n",
    "                                            with_decay=with_decay, with_plasticity=True)        \n",
    "    rates = rates[:, np.ceil(brunout * 1000).astype(int):]\n",
    "  \n",
    "    homeostatic_fittness =  np.abs(OBJ_RATE - np.mean(rates))\n",
    "    return homeostatic_fittness\n",
    "\n",
    "@scheduler.parallel(n_jobs=N_JOBS)\n",
    "def bayes_step_parallelized(DECAY, LR):\n",
    "    OBJ_RATE = 3.44\n",
    "    sampling_freq = 10000\n",
    "    nb_steps = 100000\n",
    "    C = loadmat('../SC_and_5ht2a_receptors.mat')['sc90']\n",
    "    C = 0.2 * C / np.max(C)\n",
    "    triu_idx = np.triu_indices(C.shape[1], 1)\n",
    "    brunout = 5\n",
    "    params = dmf.default_params(C=C)\n",
    "    params['N'] = C.shape[0]\n",
    "    \n",
    "    G_average_list = list(np.arange(0.5, 6.5, 0.5))\n",
    "    \n",
    "    def compute_fitness_for_G(G):\n",
    "        with_decay = DECAY > 0\n",
    "        params['lrj'] = LR\n",
    "        params['G'] = G\n",
    "        params['taoj'] = DECAY if with_decay else 10\n",
    "        params['obj_rate'] = OBJ_RATE\n",
    "        params['J'] = 0.75 * params['G'] * params['C'].sum(axis=0).squeeze() + 1\n",
    "        rates, rates_inh, _, fic_t = dmf.run(params, nb_steps,\n",
    "                                             return_rate=True, return_bold=False, return_fic=True,\n",
    "                                             with_decay=with_decay, with_plasticity=True)\n",
    "        rates = rates[:, np.ceil(brunout * 1000).astype(int):]\n",
    "\n",
    "        return np.abs(OBJ_RATE - np.mean(rates))\n",
    "\n",
    "    homeostatic_fittness_list = Parallel(n_jobs=4)(delayed(compute_fitness_for_G)(G) for G in G_average_list)\n",
    "    homeostatic_fittness = np.mean(homeostatic_fittness_list)\n",
    "    \n",
    "    return homeostatic_fittness\n",
    "\n",
    "@scheduler.serial\n",
    "def bayes_step(DECAY, LR):\n",
    "    OBJ_RATE = 3.44\n",
    "    sampling_freq = 10000\n",
    "    nb_steps = 100000\n",
    "    C = loadmat('../SC_and_5ht2a_receptors.mat')['sc90']\n",
    "    C = 0.2*C/np.max(C)\n",
    "    triu_idx = np.triu_indices(C.shape[1],1)\n",
    "    brunout = 5\n",
    "    params = dmf.default_params(C=C)\n",
    "    params['N'] = C.shape[0]\n",
    "    #print(f\"Running - G:{G} / DECAY:{DECAY} / OBJ_RATE:{OBJ_RATE} / LR:{LR} \\n\")\n",
    "    G_average_list = list(np.arange(0.5,6.5,0.5))\n",
    "    homeostatic_fittness_list = np.zeros(len(G_average_list))\n",
    "    for idx,G in enumerate(G_average_list):\n",
    "        with_decay = DECAY>0\n",
    "        params['lrj'] = LR\n",
    "        params['G'] = G\n",
    "        params['taoj'] = DECAY if with_decay else 10 # If0 it means no plasticity at all. We put some value so it does not crash\n",
    "        params['obj_rate'] = OBJ_RATE\n",
    "        #params['taoj'] = 210000\n",
    "        params['J'] = 0.75*params['G']*params['C'].sum(axis=0).squeeze() + 1\n",
    "        rates, rates_inh, _, fic_t = dmf.run(params, nb_steps,\n",
    "                                                return_rate=True, return_bold=False, return_fic=True, \n",
    "                                                with_decay=with_decay, with_plasticity=True)        \n",
    "        rates = rates[:, np.ceil(brunout * 1000).astype(int):]\n",
    "    \n",
    "        homeostatic_fittness_list[idx] = np.abs(OBJ_RATE - np.mean(rates))\n",
    "    homeostatic_fittness = np.mean(homeostatic_fittness_list)\n",
    "    return homeostatic_fittness"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 71,
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.15112935555834806: 100%|██████████| 8/8 [14:49<00:00, 111.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Best parameters: {'LR': 18.0, 'DECAY': 15400}\n",
      "Best accuracy: 0.15112935555834806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.41079289362229776: 100%|██████████| 8/8 [14:51<00:00, 111.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2:\n",
      "Best parameters: {'DECAY': 46000, 'LR': 10.0}\n",
      "Best accuracy: 0.41079289362229776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.5308633226362778: 100%|██████████| 8/8 [12:09<00:00, 91.13s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3:\n",
      "Best parameters: {'DECAY': 4400, 'LR': 148.0}\n",
      "Best accuracy: 0.5308633226362778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.3432824279063242: 100%|██████████| 8/8 [10:55<00:00, 81.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4:\n",
      "Best parameters: {'DECAY': 51600, 'LR': 8.0}\n",
      "Best accuracy: 0.3432824279063242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.44100525229979964: 100%|██████████| 8/8 [10:53<00:00, 81.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5:\n",
      "Best parameters: {'LR': 14.0, 'DECAY': 35600}\n",
      "Best accuracy: 0.44100525229979964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.07901906140600072: 100%|██████████| 8/8 [10:45<00:00, 80.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6:\n",
      "Best parameters: {'DECAY': 1200, 'LR': 336.0}\n",
      "Best accuracy: 0.07901906140600072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.5244668432702344: 100%|██████████| 8/8 [10:55<00:00, 81.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7:\n",
      "Best parameters: {'DECAY': 15800, 'LR': 38.0}\n",
      "Best accuracy: 0.5244668432702344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.8894130995258713: 100%|██████████| 8/8 [10:45<00:00, 80.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8:\n",
      "Best parameters: {'DECAY': 77000, 'LR': 14.0}\n",
      "Best accuracy: 0.8894130995258713\n",
      "\n",
      "Results for Iteration 1:\n",
      "Best parameters: {'LR': 18.0, 'DECAY': 15400}\n",
      "Best accuracy: 0.15112935555834806\n",
      "\n",
      "Results for Iteration 2:\n",
      "Best parameters: {'DECAY': 46000, 'LR': 10.0}\n",
      "Best accuracy: 0.41079289362229776\n",
      "\n",
      "Results for Iteration 3:\n",
      "Best parameters: {'DECAY': 4400, 'LR': 148.0}\n",
      "Best accuracy: 0.5308633226362778\n",
      "\n",
      "Results for Iteration 4:\n",
      "Best parameters: {'DECAY': 51600, 'LR': 8.0}\n",
      "Best accuracy: 0.3432824279063242\n",
      "\n",
      "Results for Iteration 5:\n",
      "Best parameters: {'LR': 14.0, 'DECAY': 35600}\n",
      "Best accuracy: 0.44100525229979964\n",
      "\n",
      "Results for Iteration 6:\n",
      "Best parameters: {'DECAY': 1200, 'LR': 336.0}\n",
      "Best accuracy: 0.07901906140600072\n",
      "\n",
      "Results for Iteration 7:\n",
      "Best parameters: {'DECAY': 15800, 'LR': 38.0}\n",
      "Best accuracy: 0.5244668432702344\n",
      "\n",
      "Results for Iteration 8:\n",
      "Best parameters: {'DECAY': 77000, 'LR': 14.0}\n",
      "Best accuracy: 0.8894130995258713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "lr_range = np.concatenate([np.arange(0.1, 1.1, 0.1), np.array(range(2, 401, 2))])\n",
<<<<<<< HEAD
    "pbounds = {'G': np.arange(1,6.5,0.5), 'DECAY': range(0,100001,200), 'LR':lr_range}\n",
    "conf_dict = dict(num_iteration=40, initial_random=10, batch_size=N_JOBS)"
=======
    "pbounds_withG = {'G': np.arange(1,6.5,0.5), 'DECAY': range(0,100001,200), 'LR':lr_range}\n",
    "pbounds = {'DECAY': range(0, 100001, 200), 'LR': lr_range}\n",
    "conf_dict = dict(num_iteration=8, initial_random=8)\n",
    "tuner = Tuner(pbounds, bayes_step_parallelized, conf_dict)\n",
    "\n",
    "# Create an empty list to store results\n",
    "all_results = []\n",
    "\n",
    "# Perform multiple optimization runs with different random seeds\n",
    "for iteration in range(8):\n",
    "    random_seed = iteration\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    # Minimize with the Tuner using the new random seed\n",
    "    results = tuner.minimize()\n",
    "    \n",
    "    # Append the results of this iteration to the list\n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results for the current iteration\n",
    "    print(f\"Iteration {iteration + 1}:\")\n",
    "    print('Best parameters:', results['best_params'])\n",
    "    print('Best accuracy:', results['best_objective'])\n",
    "\n",
    "# Print all results\n",
    "for i, result in enumerate(all_results, start=1):\n",
    "    print(f\"\\nResults for Iteration {i}:\")\n",
    "    print('Best parameters:', result['best_params'])\n",
    "    print('Best accuracy:', result['best_objective'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.5679424230969086: 100%|██████████| 20/20 [02:08<00:00,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'DECAY': 15600, 'G': 4.0, 'LR': 42.0}\n",
      "best accuracy: 0.5679424230969086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Serial decorator\n",
    "tuner = Tuner(pbounds_withG, bayes_step_withG, conf_dict)\n",
    "results = tuner.minimize()\n",
    "print('best parameters:', results['best_params'])\n",
    "print('best accuracy:', results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.1987530043420267: 100%|██████████| 40/40 [05:56<00:00,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'DECAY': 1400, 'G': 3.5, 'LR': 312.0}\n",
      "best accuracy: 0.1987530043420267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4 jobs\n",
    "tuner = Tuner(pbounds, bayes_step, conf_dict)\n",
    "results = tuner.minimize()\n",
    "print('best parameters:', results['best_params'])\n",
    "print('best accuracy:', results['best_objective'])"
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 53,
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Best score: 0.02076457817241506: 100%|██████████| 40/40 [10:13<00:00, 15.34s/it]"
=======
      "Best score: 0.012179817469832432: 100%|██████████| 40/40 [04:47<00:00,  7.20s/it]"
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "best parameters: {'DECAY': 78200, 'G': 1.5, 'LR': 4.0}\n",
      "best accuracy: 0.02076457817241506\n"
=======
      "best parameters: {'DECAY': 3400, 'G': 5.0, 'LR': 108.0}\n",
      "best accuracy: 0.012179817469832432\n"
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# 8 jobs\n",
=======
    "# 2 jobs\n",
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
    "tuner = Tuner(pbounds, bayes_step, conf_dict)\n",
    "results = tuner.minimize()\n",
    "print('best parameters:', results['best_params'])\n",
    "print('best accuracy:', results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 55,
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Best score: 0.0995882196725093: 100%|██████████| 40/40 [09:28<00:00, 14.22s/it]"
=======
      "Best score: 0.07216902358055544: 100%|██████████| 40/40 [04:16<00:00,  6.41s/it]"
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "best parameters: {'DECAY': 13200, 'G': 1.0, 'LR': 20.0}\n",
      "best accuracy: 0.0995882196725093\n"
=======
      "best parameters: {'DECAY': 22000, 'G': 3.0, 'LR': 16.0}\n",
      "best accuracy: 0.07216902358055544\n"
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# 4 jobs\n",
=======
    "# 1 job\n",
>>>>>>> cf0be17261db46f04e532696c516bf7e6efcebc9
    "tuner = Tuner(pbounds, bayes_step, conf_dict)\n",
    "results = tuner.minimize()\n",
    "print('best parameters:', results['best_params'])\n",
    "print('best accuracy:', results['best_objective'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
